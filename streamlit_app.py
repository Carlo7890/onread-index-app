import streamlit as st
import pandas as pd
import requests
import json
import re

# âœ… Gemini API í‚¤
API_KEY = st.secrets["gemini_api_key"]

# âœ… ì¤‘ë³µ ë‹¨ì–´ ì˜ë¯¸ ê¸°ì¤€
ambiguous_meanings = {
    "ê¸°ìˆ ": {"2": "ê¸°ëŠ¥/ë°©ë²•", "3": "ê¸°ë¡/ì„œìˆ "},
    "ìœ í˜•": {"2": "ê³µí†µì ì¸ ê²ƒë¼ë¦¬ ë¬¶ì€ í‹€", "3": "í˜•ì²´ê°€ ìˆëŠ” ê²ƒ"},
    "ì˜ì§€": {"2": "ì´ë£¨ê³ ì í•˜ëŠ” ë§ˆìŒ", "3": "ì˜ì§€í•˜ë‹¤ (ê¸°ëŒ€ë‹¤)"},
    "ì§€ì ": {"2": "ì§€ì‹œ/ì§€ëª©", "3": "ì§€ì‹ì´ë‚˜ ì§€ì„±ì— ê´€í•œ ê²ƒ"}
}

# âœ… ì¤‘ë³µ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
ambiguous_words = list(ambiguous_meanings.keys())

# âœ… Gemini ë¬¸ë§¥ ë“±ê¸‰ íŒë‹¨ í•¨ìˆ˜
def classify_ambiguous_word(word, sentence):
    meaning = ambiguous_meanings.get(word)
    prompt = f"""
    ë¬¸ì¥: "{sentence}"
    ë‹¨ì–´: "{word}"

    ë‹¤ìŒ ì¤‘ ì–´ë–¤ ì˜ë¯¸ë¡œ ì“°ì˜€ëŠ”ê°€?

    - 2ë“±ê¸‰ ì˜ë¯¸: {meaning['2']}
    - 3ë“±ê¸‰ ì˜ë¯¸: {meaning['3']}

    ë¬¸ë§¥ì— ë§ëŠ” ë“±ê¸‰ì„ ìˆ«ìë¡œë§Œ ì •í™•í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”. (2 ë˜ëŠ” 3)
    """

    url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    response = requests.post(f"{url}?key={API_KEY}", headers=headers, data=json.dumps(data))
    try:
        reply = response.json()["candidates"][0]["content"]["parts"][0]["text"].strip()
        if "2" in reply:
            return 2
        elif "3" in reply:
            return 3
    except:
        return None

# âœ… ì‚¬ê³ ë„êµ¬ì–´ CSV ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_vocab(csv_path="ì‚¬ê³ ë„êµ¬ì–´(1~4ë“±ê¸‰)(ê°€ê³µ).csv"):
    df = pd.read_csv(csv_path)
    vocab_dict = {}
    for col_idx, level in enumerate([1, 2, 3, 4]):
        col = df.columns[col_idx]
        words = df[col].dropna().astype(str).str.strip()
        for word in words:
            if word in ambiguous_words:
                continue  # ì¤‘ë³µ ë‹¨ì–´ëŠ” Geminië¡œ ì²˜ë¦¬
            vocab_dict[word] = level
    return vocab_dict

# âœ… ë“±ê¸‰ ë²”ìœ„ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_grade_ranges(path="ì˜¨ë…ì§€ìˆ˜ë²”ìœ„.csv"):
    df = pd.read_csv(path)
    ranges = []
    for _, row in df.iterrows():
        try:
            start, end = map(int, str(row["ì˜¨ë…ì§€ìˆ˜ ë²”ìœ„"]).split("~"))
            ranges.append((start, end, row["ëŒ€ìƒ í•™ë…„"]))
        except:
            continue
    return ranges

# âœ… ì˜¨ë…ì§€ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculate_onread_index(text, vocab_dict, grade_ranges):
    tokens = re.findall(r"[\wê°€-í£]+", text)
    seen, used, total, weighted = set(), [], 0, 0

    for token in tokens:
        base = token.strip()
        if base in ambiguous_words:
            level = classify_ambiguous_word(base, text)
            if level:
                seen.add(base)
                used.append((base, level))
                total += 1
                weighted += level
            continue
        for vocab_word, level in vocab_dict.items():
            if vocab_word in base:
                if base not in seen:
                    seen.add(base)
                    used.append((base, level))
                    total += 1
                    weighted += level
                break

    if total == 0:
        return 0, "ì‚¬ê³ ë„êµ¬ì–´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", [], 0, 0

    cttr = min(len(seen) / (2 * total)**0.5, 1.0)
    norm_weight = weighted / (4 * total)
    density = total / len(tokens)
    index = ((0.7 * cttr + 0.3 * norm_weight) * 500 + 100) * (0.5 + 0.5 * density)

    matched = [g for s, e, g in grade_ranges if s <= index < e]
    level = "~".join(matched) if matched else "í•´ì„ ë¶ˆê°€"
    return round(index), level, used, total, len(tokens)

# âœ… Streamlit UI êµ¬ì„±
st.title("ğŸ“˜ ì˜¨ë…ì§€ìˆ˜ ë¶„ì„ê¸° (Gemini ë³´ì¡° ê¸°ë°˜)")
vocab_dict = load_vocab()
grade_ranges = load_grade_ranges()

text = st.text_area("ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”", key="manual")
if st.button("ğŸ” ë¶„ì„í•˜ê¸°"):
    if text.strip():
        score, level, used_words, total_count, total_words = calculate_onread_index(text, vocab_dict, grade_ranges)
        if score == 0:
            st.warning(level)
        else:
            st.success(f"âœ… ì˜¨ë…ì§€ìˆ˜: {score}ì  ({level})")
            st.caption(f"ì´ ë‹¨ì–´ ìˆ˜: {total_words}, ì‚¬ê³ ë„êµ¬ì–´ ìˆ˜: {total_count}")
            if total_count < 3:
                st.info("ë¬¸ì¥ì´ ì§§ê±°ë‚˜ ì‚¬ê³ ë„êµ¬ì–´ê°€ ì ì–´ ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if score > 500:
                st.info("ğŸ’¡ ê³ 3 ì´ìƒ ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìš° ë†’ì€ ì‚¬ê³  ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
            if used_words:
                st.markdown("### ì‚¬ìš©ëœ ì‚¬ê³ ë„êµ¬ì–´")
                for w, l in used_words:
                    st.markdown(f"- **{w}**: {l}ë“±ê¸‰")
    else:
        st.warning("â— ë¬¸ì¥ì„ ì…ë ¥í•œ ë’¤ 'ë¶„ì„í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
